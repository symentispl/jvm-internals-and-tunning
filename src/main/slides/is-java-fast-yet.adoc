== Is Java fast yet?

=== it depends

=== !

it depends on couple of factors

=== !

do you know and understand how JIT works and how it optimizes your code?

=== !

do you know and understand how GC works and how it impacts your performance?

=== !

do you know and understand Java Memory Model and how it impacts concurrent code?

=== !

do you know and understand how OS I/O and JVM work?

=== !

do you know and understand JDK data structures' (especially collections)
performance characteristics?

=== and last but not least

do you measure your code performance?

== benchmarking

is hard

=== !

but any claims on Internet that something is fast or slow are useless without
backing benchmarking code

=== magic

there is no magic spell that makes your code fast,

no secret ingredients,

code, benchmark, profile, repeat

=== !

observability is key

== !

[quote,,Wikipedia]
  In control theory, observability is a measure of how well internal states of
  a system can be inferred from knowledge of its external outputs.
  The observability and controllability of a system are mathematical duals.

=== macro and micro

* micro, a performance of a single function
* macro, a performance of a whole system

=== bad practice

[source,java]
----
long start = System.currentTimeMillis();
for(int i=0;i<100000;i++){
  // do stuff
}
long stop = System.currentTimeMillis();
----

=== why?

* because JIT (will talk about it later)
* `System.currentTimeMillis()` precission
* it gives you numbers, but doesn't help you understand

[role="highlight_title"]
== Java Microbenchmark Harness

image::https://static.pexels.com/photos/45202/brownie-dessert-cake-sweet-45202.jpeg[background]

== !

[quote,,Wes Dyer]
  Make it correct, make it clear, make it concise, make it fast. In that order.

== !

[quote,JMH wiki,]
  JMH is a Java harness for building, running, and analysing nano/micro/milli/macro benchmarks written in Java and other languages targetting the JVM.

== !

http://openjdk.java.net/projects/code-tools/jmh/[http://openjdk.java.net/projects/code-tools/jmh/]

mvn archetype:generate \ +
       -DinteractiveMode=false \ +
       -DarchetypeGroupId=org.openjdk.jmh \ +
       -DarchetypeArtifactId=jmh-java-benchmark-archetype \ +
       -DgroupId=org.sample \ +
       -DartifactId=test \ +
       -Dversion=1.0



== benchmarks

these are public non-static methods annotated with `@Benchmark`

[source, java]
----
import org.openjdk.jmh.annotations.Benchmark;

public class CodeBenchmark {

  @Benchmark
  public void testMethod(){
  }

}
----

== managing state & life cycle

more complex examples will need to work with some data (state), +
this is what for state objects are for

[%notitle]
=== state objects

[source,java]
----
@State(Scope.Benchmark)
public class CodeBenchmarkState{

  public final ArrayList<Integer> list = new ArrayList<>();

}
----

[%notitle]
=== injecting state objects

[source,java]
----
public class CodeBenchmark{

  @Benchmark
  public void testMethod(CodeBenchmarkState state){
    state.add(0);
  }

}
----

=== note on scopes

=== Scope.Benchmark

With benchmark scope, all instances of the same type will be shared across all worker threads

=== Scope.Group

With group scope, all instances of the same type will be shared across all threads within the same group. Each thread group will be supplied with its own state object

=== Scope.Thread

With thread scope, all instances of the same type are distinct, even if multiple  state objects are injected in the same benchmark

=== lifecycle

every state object can have `@Setup` and `@TearDown` fixture methods

== time for first benchmark

let's compare iteration speed over primitive array, `ArrayList` and `LinkedList`

== running benchmarks

[source, console]
----
mvn package
java -jar target/benchmark.jar
----

=== forks, warm ups and iterations

by default JMH forks JVM for each run of benchmark, +
within each fork you have two phases

* warm up
* iteration

number of repetitions of each phase can be controlled over command line

== command line

-f  - number of forks +
-wi - number of warm ups +
-i  -  number of iterations

[%notitle]
=== command line example

[source,console]
----
java -jar target/benchmark.jar -f 1 -i 5 -wi 5
----

== parameterized tests

JMH supports parameterized tests through `@Param` annotation +
Test parameters should be public non-final fields on state objects +
they are injected right before call to setup fixture methods

[%notitle]
=== parameterized tests example

[source, java]
----
@State(Scope.Benchmark)
public class CodeBenchmark {

  @Param{"0.1","0.2","0.5","0.75","1.0"}
  public float loadFactor;

  private Map<String,String> map;

  @Setup
  public void setUp(){
    map = new HashMap<>(16,loadFactor);
  }

}
----

=== controlling parameters

you overwrite values of the parameters with command line options

[source, console]
----
java -jar target/benchmarks.jar -p loadFactor=0.8,0.9
----

[role="highlight_title"]
== dead code

image::https://static.pexels.com/photos/34153/pexels-photo.jpg[background, size=cover]

== ... and black holes

=== !

one of the dangers JMH tries to mitigate is dead code optimization from JIT, +
to avoid it, consume return values from functions with black holes

[source, java]
----
@Benchmark
public void testMethod(Blackhole blackhole){
  blackhole.consume(codeBenchmark());
}
----

[role="highlight_title"]
== asymmetric tests

image::https://static.pexels.com/photos/632445/pexels-photo-632445.jpeg[background, size=cover]

=== !
sometimes you want to benchmark your concurrent code, +
like performance of read and write paths +
this is where `@Group` and `@GroupThreads` come in

[%notitle]
=== asymetric tests example

[source, java]
----
@State(Scope.Benchmark)
public class CodeBenchmark {

	@Benchmark
	@Group("benchmarkGroup")
	@GroupThreads(1)
	public void testWrites() {
	}

	@Benchmark
	@Group("bechmarkGroup")
	@GroupThreads(1)
	public void testReads(Blackhole blackhole) {
	}

}
----

== time for third benchmark

compare performance of various thread-safe counter implementations

[source, java]
----
public class Counter {

	private long counter;

	public void inc() {
		++counter;
	}

	public long counter() {
		return counter;
	}
}
----

== profilers

they can provide some insights into your code

[source, console]
----
java -jar benchmark.jar -lprof
java -jar benchmark.jar -prof hs_gc
----

=== useful builtin profilers

* safepoint
* perfasm
* jfr
* async

== reporters

and last but not least, writing test results to files

[source, console]
----
java -jar benchmark.jar -lr
java -jar benchmark.jar -rf csv -rff results.csv
----

== tips and tricks

CPU governors can trick you, +
it's easy to control them on Linux with `cpufreq-set`

== flamegraphs

[quote,,Brendan Greg]
  Flame graphs are a visualization of profiled software, allowing
  the most frequent code-paths to be identified quickly and accurately.
  They can be generated using my open source programs on github.com/brendangregg/FlameGraph,
  which create interactive SVGs

== flame graphs with JMH

  sudo sysctl kernel.perf_event_paranoid=-1
  sysctl kernel.kptr_restrict=0
  export ASYNC_PROFILER_DIR=/home/jarek/tools/async-profiler
  
  LD_LIBRARY_PATH=/home/jarek/tools/async-profiler/lib/ java -jar perf/target/benchmarks.jar \
  "introdb.heap.ReadUnorderedHeapFileBenchmark.readKey"  -f 1 \
  -prof "async:output=flamegraph" \
  -p bufferSize=512


=== !

image::introdb.heap.ReadUnorderedHeapFileBenchmark.readKey.svg[background, size=contain]

=== what about macro?

(this is not a scope of this training)

* JMeter
* Gatling
* k6s

=== why my code is slow?

sometimes you write code that's supposed to be fast, +
as f..k, +
according to all best practices ever described +

and it is sometimes slow, +
with no reason


[role="highlight_title"]
=== let's dive in

image::blue-deep-diver-94241.jpg[background]

== !
