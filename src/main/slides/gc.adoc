== Garbage collection

=== Agenda

* Garbage collection techniques
* Understanding reference tracing
* Generational garbage collection
* Garbage collection in JVM
* Garbage collection performance and tuning

=== Garbage collection techniques

* Reference counting
* Reference tracing
* Reference scope

=== Reference tracing

[graphviz]
----
digraph {
	A->B
	A->C
	A->D

	B->E
	C->E

	F->G
	G->H

  I->J

  A [label="A (GC Root)"]
  F [label="F (GC Root)"]
  I [label="I (unreachable)"]
  J [label="J (unreachable)"]

}
----

=== Root set

* An object is alive if it is referenced by a live object
* An object is alive if a static reference to it exists (part of the root set)
* An object is alive if a stack reference to it exists (part of the root set)
* An object is alive if a object is part of root set

=== Mark, sweep & copy

There are three major types of reference tracing garbage collectors

* *mark & sweep*, which contain to main phases, marking phase and sweep phase,
downside is that it leaves heap fragmented, it requires to maintain free list
* *mark, sweep & copy*, it adds additional phase during which we copy
objects to new region, to avoid defragmentation, which requires copying object
and updating references to it
* *mark, sweep & compat*, it compacts heap, when it is not able to allocate
continuous memory region for new object

=== Stop the world

Reference tracing collectors require "stop the world" pause, which means
we stop all threads which mutate application heap.

=== Generational garbage collection

[quote,,memorymanagement.org]
	Generational garbage collection is tracing garbage collection that makes
	use of the generational hypothesis. Objects are gathered together in
	generations. New objects are allocated in the youngest or nursery
	generation, and promoted to older generations if they survive. Objects
	in older generations are condemned less frequently, saving CPU time.

=== !

[quote,,memorymanagement.org]
	It is typically rare for an object to refer to a younger object. Hence,
	objects in one generation typically have few references to objects in
	younger generations. This means that the scanning of old generations in
	the course of collecting younger generations can be done more efficiently
	by means of remembered sets.

=== !

[quote,,memorymanagement.org]
	In some purely functional languages (that is, without update), all
	references are backwards in time, in which case remembered sets
	are unnecessary.

=== Garbage collection in JVM

This is where things get hairy

* Object allocation (TLAB)
* Oops maps
* Card-marking
* Write/read barriers
* Global safepoints

=== !

* Old collectors
** ParallelOld GC
** ConcurrentMarkSweep GC
* Footprint vs throughput vs pause
* next generation collectors
** G1 GC
** Shenandoah GC
** ZGC GC
** Epsilon GC

=== Object allocation in TLAB

[ditaa]
----
Thread1    Thread2    Thread3    Thread4
+---+----+ +--------+ +--------+ +--------+
|   |    | |        | |        | |        |
|   |    | |        | |        | |        |
+---+----+ +--------+ +--------+ +--------+
----

=== Card marking

[quote,Brian Goetz,GC in the HotSpot JVM]
	Tracing garbage collectors, such as copying, mark-sweep, and mark-compact,
	all start scanning from the root set, traversing references between objects,
	until all live objects have been visited. A generational tracing collector
	starts from the root set, but does not traverse references that lead to
	objects in the older generation, which reduces the size of the object
	graph to be traced. But this creates a problem -- what if an object in the
	older generation references a younger object, which is not reachable through
	any other chain of references from a root?

=== !

[quote,Brian Goetz,GC in the HotSpot JVM]
	Whether an old-to-young reference is created by promotion or a pointer
	modification, the garbage collector needs to have a comprehensive set
	of old-to-young references when it wants to perform a minor collection.
	One way to do this would be to trace the old generation, but this clearly
	has significant overhead. Somewhat better would be to linearly scan the
	old generation looking for references to young objects. This approach is
	faster than tracing and has better locality, but is still considerable work.

=== !

[quote,Brian Goetz,GC in the HotSpot JVM]
 JDKs use an optimized variant of an algorithm called card marking to identify
 modifications to pointers held in fields of old-generation objects. In this
 approach, the heap is divided into a set of cards, each of which is usually
 smaller than a memory page. The JVM maintains a card map, with one bit
 (or byte, in some implementations) corresponding to each card in the heap.
 Each time a pointer field in an object in the heap is modified, the
 corresponding bit in the card map for that card is set.


=== !

[quote,Brian Goetz,GC in the HotSpot JVM]
 At garbage collection time, the mark bits associated with cards in the old
 generation are examined, and dirty cards are scanned for objects containing
 references into the younger generation. Then the mark bits are cleared.
 There are several costs to card marking – additional space for the card
 map, additional work to be done on each pointer store, and additional
 work to be done at garbage collection time. Card marking algorithms can
 add as little as two or three machine instructions per non-initializing
 heap pointer store, and entails scanning any objects on dirty cards at
 minor collection time.


=== Read/write barriers

[quote,Alexey Ragozin,Understanding GC pauses in JVM, HotSpot's minor GC]
	Principle of dirty card write-barrier is very simple. Each time when program
	modifies reference in memory, it should mark modified memory page as dirty.
	There is a special card table in JVM and each 512 byte page of memory has
	associated byte in card table.

=== !

[quote,Nitsan Wakart,The JVM Write Barrier - Card Marking]
	So setting a reference throws in the overhead of a few instructions,
	which boil down to:
	 CARD_TABLE [this address >> 9] = 0;
	This is significant overhead when compared to primitive fields, but is
	considered necessary tax for memory management. The tradeoff here is
	between the benefit of card marking (limiting the scope of required
	old generation scanning on young generation collection) vs.
	the fixed operation overhead for all reference writes. The associated write
	to memory for card marking can sometimes cause performance issues for
	highly concurrent code. This is why in OpenJDK7 we have a new option called
	UseCondCardMark.

=== Conditional card marking

=== Usefull links

http://psy-lob-saw.blogspot.com/2014/10/the-jvm-write-barrier-card-marking.html[The JVM Write Barrier - Card Marking] +
https://www.ibm.com/developerworks/library/j-jtp11253/[Garbage collection in the HotSpot JVM] +
http://blog.ragozin.info/2011/06/understanding-gc-pauses-in-jvm-hotspots.html[Understanding GC pauses in JVM, HotSpot's minor GC] +

=== Global safepoint

[quote,Nitsan Wakart,Safepoints: Meaning, Side Effects and Overheads ]
A safepoint is a range of execution where the state of the executing thread is well described. Mutator threads are threads which manipulate the JVM heap (all your Java Threads are mutators. Non-Java threads may also be regarded as mutators when they call into JVM APIs which interact with the heap).
At a safepoint the mutator thread is at a known and well defined point in it's interaction with the heap. This means that all the references on the stack are mapped (at known locations) and the JVM can account for all of them. As long as the thread remains at a safepoint we can safely manipulate the heap + stack such that the thread's view of the world remains consistent when it leaves the safepoint.

=== !

[quote,Nitsan Wakart,Safepoints: Meaning, Side Effects and Overheads ]
	A JVM will therefore need means of bringing threads to safepoints
	(and keeping them there) so that all sorts of runtime magic can happen.
	Here's a partial list of activities which JVMs run only once all mutator
	threads are at a safepoint and cannot leave it until released
	(at a global safepoint), these are sometime called safepoint operations:

=== !

	 * Some GC phases (the Stop The World kind)
	 * JVMTI stack sampling methods (not always a global safepoint operation for Zing))
	 * Class redefinition
	 * Heap dumping
	 * Monitor deflation (not a global safepoint operation for Zing)
	 * Lock unbiasing
	 * Method deoptimization (not always)
	 * And many more!

=== Safepoint polling

[quote,Nitsan Wakart,Safepoints: Meaning, Side Effects and Overheads ]
	So having threads at a safepoint allows the JVM to get on with it's managed
	runtime magic show, great! When is this groovy state happening?


=== !

	 * A Java thread is at a safepoint if it is blocked on a lock or synchronized block, waiting on a monitor, parked, or blocked on blocking IO. Essentially these all qualify as orderly de-scheduling events for the Java thread and as part of tidying up before put on hold the thread is brought to a safepoint.
	 * A Java thread is at a safepoint while executing JNI code. Before crossing the native call boundary the stack is left in a consistent state before handing off to the native code. This means that the thread can still run while at a safepoint.
	 * A Java thread which is executing bytecode is NOT at a safepoint (or at least the JVM cannot assume that it is at a safepoint).
	 * A Java thread which is interrupted (by the OS) while not at a safepoint is not brought to a safepoint before being de-scheduled.

=== !

The JVM and your running Java threads have the following relationship around safepoints:

* The JVM cannot force any thread into a safepoint state.
* The JVM can stop threads from leaving a safepoint state.

So how can the JVM bring all threads into a safepoint state? The problem is suspending a thread at a known state, not just interrupting it. To achieve this goal JVMs have the Java threads suspend themselves at convenient spots if they observe a 'safepoint flag'.

=== !

[quote,Nitsan Wakart,Safepoints: Meaning, Side Effects and Overheads ]
	These considerations combined lead to the following locations for safepoint polls:

=== !

    * Between any 2 bytecodes while running in the interpreter (effectively)
    * On 'non-counted' loop back edge in C1/C2 compiled code
    * Method entry/exit (entry for Zing, exit for OpenJDK) in C1/C2 compiled code. Note that the compiler will remove these safepoint polls when methods are inlined.

=== Time to Safepoint

[quote,Nitsan Wakart,Safepoints: Meaning, Side Effects and Overheads ]
	Each thread enters a safepoint when it hits a safepoint poll. But arriving at
	a safepoint poll requires executing an unknown number of instructions.
	We can see J1 hits a safepoint poll straight away and is suspended.
	J2 and J3 are contending on the availability of CPU time. J3 grabs some CPU
	time pushing J2 into the run queue, but J2  is not in a safepoint.
	J3 arrives at a safepoint and suspends, freeing up the core for J2 to make
	enough progress to get to a safepoint poll.


=== Time to Safepoint

[quote,Nitsan Wakart,Safepoints: Meaning, Side Effects and Overheads ]
	J4 and J5 are already at a safepoint while executing JNI code, they are
	not affected. Note that J5 is trying to leave JNI halfway through the
	safepoint and is suspended before resuming Java code. Importantly we
	observe that the time to safepoint varies from thread to thread and
	some threads are paused for longer than others, Java threads which take
	a long time to get to a safepoint can
	delay many other threads.

=== Diagnostics

JDK 8 and previous versions

`-XX:+PrintGCApplicationStoppedTime` +
`-XX:+PrintSafepointStatistics`

JDK 9 and later

`-Xlog:safepoint=debug`


=== Usefull links

https://medium.com/software-under-the-hood/under-the-hood-java-peak-safepoints-dd45af07d766[Under the hood JVM: Safepoints] +
https://shipilev.net/jvm/anatomy-quarks/22-safepoint-polls/[JVM Anatomy Quark #22: Safepoint Polls] +
http://psy-lob-saw.blogspot.com/2015/12/safepoints.html[Safepoints: Meaning, Side Effects and Overheads] +
https://psy-lob-saw.blogspot.com/2014/03/where-is-my-safepoint.html[Where is my safepoint?] +
https://richardstartin.github.io/posts/garbage-collector-code-artifacts-card-marking[Garbage Collector Code Artifacts: Card Marking]

=== Parallel GC

* The majority of newly created objects are located in the Eden space.
* After one GC in the Eden space, the surviving objects are moved to one of the Survivor spaces.
* After a GC in the Eden space, the objects are piled up into the Survivor space, where other surviving objects already exist.
* Once a Survivor space is full, surviving objects are moved to the other Survivor space. Then, the Survivor space that is full will be changed to a state where there is no data at all.
* The objects that survived these steps that have been repeated a number of times are moved to the old generation.

=== Heap in JVM

[ditaa]
----
+---------------------------+-----------------+-----------------+
|            New            |    Survivor0    |    Survivor1    |
+---------------------------+-----------------+-----------------+
|                        Tenured/Old                            |
+---------------------------------------------------------------+

+---------------------------------------------------------------+
|                         Metaspace                             |
+---------------------------------------------------------------+
----

=== Object age

=== ParallelOld GC

[quote,,Java Collection Handbook]
	This combination of Garbage Collectors uses mark-copy in the Young Generation
	and mark-sweep-compact in the Old Generation. Both Young and Old collections
	trigger stop-the-world events, stopping all application threads to perform
	garbage collection. Both collectors run marking and copying / compacting
	phases using multiple threads, hence the name ‘Parallel’.
	Using this approach, collection times can be considerably reduced.
	The number of threads used during garbage collection is configurable via the
	command line parameter `-XX:ParallelGCThreads=NNN`. The default value is
	equal to the number of cores in your machine.

=== ConcurrentMarkSweep GC

[quote,,]
	Following up on the parallel collector is the CMS collector
	(“concurrent-mark-sweep”). This algorithm uses multiple threads (“concurrent”)
	to scan through the heap (“mark”) for unused objects that can be recycled
	(“sweep”). This algorithm will enter “stop the world” (STW) mode in
	two cases: when initializing the initial marking of roots
	(objects in the old generation that are reachable from thread entry points or
	static variables) and when the application has changed the state of the
	heap while the algorithm was running concurrently, forcing it to go back and
 	do some final touches to make sure it has the right objects marked.

=== Footprint vs throughput vs pause

Three main GC properties

* footprint, how much heap is needed
* throughput, how much time is spent in application vs in GC
* pause, for how long application is stopped, not doing any work

=== !

* `-Xmx`, footprint target
* `-XX:MaxGCPauseMillis=200`, pause target
* `-XX:GCTimeRatio=12`, throughput target
* `-XX:+AdaptiveSizePolicy`, adaptive generation sizing

=== Problems with old collectors

* generation sizing (people were spending too much time on this)
* even with adaptive sizing policy, which still poorly responded to memory
application pressure changes
* due to whole-heap GC, long pauses on large heaps

=== G1 GC

aka Garbage First

the goal of the G1 collector is to achieve a predictable soft-target pause time,
defined through `-XX:MaxGCPauseMillis`, while also maintaining consistent
application throughput

A general rule with G1 is that the higher the pause time target, the achievable
throughput, and overall latency become higher. The lower the pause time target,
the achievable throughput and overall latency become lower.

=== G1 regions

a region represents a block of allocated space that can hold objects of any
generation without the need to maintain contiguity with other regions of
the same generation. In G1, the traditional Young and Tenured generations still
exist. The young generation consists of Eden space, where all newly allocated
objects start and Survivor space, where live eden objects are copied to during
a collection. Objects remain in the Survivor space until they are either
collected or old enough for promotion, defined by the `-XX:MaxTenuringThreshold`
(defaults to 15). The Tenured generation consists of the Old space, where
objects are promoted from the Survivor space when they reach the
`-XX:MaxTenuringThreshold`


=== !

The region size is calculated and defined when the JVM starts. It is based on
the principle of having as close to 2048 regions as possible where each region
is sized as a power of 2 between 1 and 64 MB.
You also have the option of explicitly specifying the region size through
-XX:G1HeapRegionSize. When setting the region size, it’s important to
understand the number of regions your heap-to-size ratio will create because
the fewer the regions, the less flexibility G1 has and the longer it takes
to scan, mark and collect each of them. In all cases, empty regions are
added to an unordered linked list also known as the "free list".

=== !

When object production begins, a region is allocated from the free list as a
thread-local allocation buffer (TLAB) using a compare and swap methodology to
achieve synchronization. Objects can then be allocated within those
thread-local buffers without the need for additional synchronization.
When the region has been exhausted of space, a new region is selected,
allocated and filled. This continues until the cumulative Eden region space
has been filled, triggering an evacuation pause
(also known as a young collection / young gc / young pause
	or mixed collection / mixed gc / mixed pause). The cumulative amount of
Eden space represents the number of regions we believe can be collected within
the defined soft pause time target. The percentage of total heap allocated for
Eden regions can range from 5% to 60% and gets dynamically adjusted after
each young collection based on the performance of the previous young collection.

=== !

When the aforementioned young collection takes place, dead objects are
collected and any remaining live objects are evacuated and compacted into
the Survivor space. G1 has an explicit hard-margin, defined by the
G1ReservePercent (default 10%), that results in a percentage of the heap
always being available for the Survivor space during evacuation. Without this
available space, the heap could fill to a point in which there are no
available regions for evacuation. There is no guarantee this will not still
happen, but that’s what tuning is for! This principle ensures that after
every successful evacuation, all previously allocated Eden regions are
returned to the free list and any evacuated live objects end up
in Survivor space.

=== !

Continuing with this pattern, objects are again allocated into newly
requested Eden regions. When Eden space fills up, another young
collection occurs and, depending on the age (how many young collections
the various objects have survived) of existing live objects,
you will see promotion to Old regions. Given the Survivor space is part of
the young generation, dead objects are collected or promoted during
these young pauses.

=== !

G1 will continue with this pattern until one of three things happens:

* It reaches a configurable soft-margin known as the InitiatingHeapOccupancyPercent.
* It reaches its configurable hard-margin (G1ReservePercent)
* It encounters a humongous allocation (will talk about it later).


=== !

Liveness ratio (InitiatingHeapOccupancyPercent) is constantly being calculated
and evaluated as a component of each young collection. When one of these
triggers are hit, a request is made to start a concurrent marking cycle.

=== !

In G1, concurrent marking is based on the principle of
snapshot-at-the-beginning (SATB). This means, for efficiency purposes,
it can only identify objects as being garbage if they existed when the
initial snapshot was taken. Any newly allocated objects that appear during the
concurrent marking cycle are considered to be live irrespective of their
true state. This is important because the longer it takes for concurrent
marking to complete, the higher the ratio will be of what is collectible
versus what is considered to be implicitly live. If you allocate more
objects during concurrent marking than you end up collecting, you will
eventually exhaust your heap. During the concurrent marking cycle, you will
see young collections continue as it is not a stop-the-world event.

=== !

Once the concurrent marking cycle completes, a young collection is immediately
triggered, followed by a second type of evacuation, known as a mixed collection.
A mixed collection works almost exactly like a young collection, with two major
differences. First, a mixed collection is also going to collect, evacuate and
compact a select set of old regions. Second, mixed collections are not based
on the same evacuation triggers a young collection uses. They operate with
the goal of collecting as quickly and as frequently as possible. They do this
to minimize the number of allocated Eden / Survivor regions in order to
maximize the number of Old regions selected within the soft pause target.

=== !

`G1HeapWastePercent` defines threshold, percentage of liveset, which triggers
old region collection during mixed collection.

Because we don’t want to perform wasted work, G1 stays true to the garbage
first policy. Based on an ordered list, candidate regions are selected based
on their live object percentage. If an Old region has fewer live objects than
the percentage defined by `G1MixedGCLiveThresholdPercent`
(defaults to 85% in JDK8u40+ and 65% in JDK7), we add it to the list. Simply put,
if an Old region is greater than 65% (JDK7) or 85% (JDK8u40+) live,
we don’t want to waste our time trying to collect and evacuate it during
this mixed cycle.

=== !

Compared to a young collection, a mixed collection will look to collect all
three generations within the same pause time target. It manages this through
the incremental collection of the Old regions based on the value of
`G1MixedGCCountTarget` (defaults to 8). Meaning, it will divide the number
of candidate Old regions by the G1MixedGCCountTarget and try to collect at
least that many regions during each cycle. After each cycle finishes,
the liveness of the Old region is re-evaluated. If the reclaimable space is
still greater than the G1HeapWastePercent, mixed collections will continue.

=== !

* Humongous allocation represents a single object, and as such, must be allocated into contiguous space. This can lead to significant fragmentation.
* Humongous objects are allocated to a special humongous region directly within the Old generation. This is because the cost to evacuate and copy such an object across the young generations can be too high.
* Even though the object in question is only 12.5 MB, it must consume four full regions accounting for 16 MB of total usage.
* Humongous allocations always trigger a concurrent marking cycle, whether the IHOP criteria is met or not.

=== !

card marking in G1 uses write barrier (armed before concurrent marking starts)
updates stored in buffer associated with region, which after concurrent mark
phase update cards

=== Useful links

https://en.wikipedia.org/wiki/Garbage-first_collector[Garbage First Collector] +
https://www.dynatrace.com/news/blog/understanding-g1-garbage-collector-java-9/[Understanding G1 Garbage Collector] +
https://docs.oracle.com/javase/8/docs/technotes/guides/vm/gctuning/g1_gc.html[Tuning G1 GC] +
https://www.redhat.com/en/blog/part-1-introduction-g1-garbage-collector[Introduction to G1 Garbage Collector] +
https://plumbr.io/handbook/garbage-collection-algorithms-implementations/g1[Garbage Collection Algorithms Implementation]

=== Shenandoah GC

Shenandoah is the low pause time garbage collector that reduces GC pause times
by performing more garbage collection work concurrently with the running Java
program. Shenandoah does the bulk of GC work concurrently, including the
*concurrent compaction*, which means its pause times are no longer directly
proportional to the size of the heap. Garbage collecting a 200 GB
heap or a 2 GB heap should have the similar low pause behavior.

=== !

Shenandoah is the regionalized collector, it maintains the heap as the collection of regions.

=== !

*Init Mark* initiates the concurrent marking. It prepares the heap and application threads for concurrent mark, and then scans the root set. This is the first pause in the cycle, and the most dominant consumer is the root set scan. Therefore, its duration is dependent on the root set size.

=== !

*Concurrent Marking* walks over the heap, and traces reachable objects. This phase runs alongside the application, and its duration is dependent on the number of live objects and the structure of object graph in the heap. Since the application is free to allocate new data during this phase, the heap occupancy goes up during concurrent marking.

=== !

*Final Mark* finishes the concurrent marking by draining all pending marking/update queues and re-scanning the root set. It also initializes evacuation by figuring out the regions to be evacuated (collection set), pre-evacuating some roots, and generally prepares runtime for the next phase. Part of this work can be done concurrently during Concurrent precleaning phase. This is the second pause in the cycle, and the most dominant time consumers here are draining the queues and scanning the root set.

=== !

*Concurrent Cleanup* reclaims immediate garbage regions – that is, the regions where no live objects are present, as detected after the concurrent mark.

=== !

*Concurrent Evacuation* copies the objects out of collection set to other regions. This is the major difference against other OpenJDK GCs. This phase is again running along with application, and so application is free to allocate. Its duration is dependent on the size of chosen collection set for the cycle.

=== !

*Init Update Refs* initializes the update references phase. It does almost nothing except making sure all GC and applications threads have finished evacuation, and then preparing GC for next phase. This is the third pause in the cycle, the shortest of them all.

=== !

*Concurrent Update References* walks over the heap, and updates the references to objects that were moved during concurrent evacuation. This is the major difference against other OpenJDK GCs. Its duration is dependent on number of objects in heap, but not the object graph structure, because it scans the heap linearly. This phase runs concurrently with the application.

=== !

*Final Update Refs* finishes the update references phase by re-updating the existing root set. It also recycles the regions from the collection set, because now heap does not have references to (stale) objects to them. This is the last pause in the cycle, and its duration is dependent on the size of root set.

=== !

*Concurrent Cleanup* reclaims the collection set regions, which now have no references to.

=== Concurrent compaction

[quote,,An open-source concurrent compacting garbage collector for OpenJDK]
	Concurrent compaction is complicated because along with
	moving a potentially in-use object, you also have to atom-
	ically update all references to that object to point to the
	new location. Simply finding those references may require
	scanning the entire heap. Our solution is to add a forward-
	ing pointer to each object, and requiring all uses of that
	object to go through the forwarding pointer.

=== Concurrent compaction

[quote,,An open-source concurrent compacting garbage collector for OpenJDK]
	This protocol allows us to move the object while the Java threads are
	running. The GC threads and the mutator threads copy the
	objects and use an atomic compare and swap (CAS) to update the
	forwarding pointer. If multiple GC and mutator
	threads were competing to move the same object only one
	CAS would succeed. References are updated during the next
	concurrent marking gc phase.

=== updates in JDK 12 & 13

Forwarding pointer is no longer needed.

=== Useful links

https://developers.redhat.com/blog/2019/07/01/shenandoah-gc-in-jdk-13-part-3-architectures-and-operating-systems/
https://shipilev.net/talks/jugbb-Sep2019-shenandoah.pdf
https://rkennke.wordpress.com/

=== ZGC

https://hub.packtpub.com/getting-started-with-z-garbage-collectorzgc-in-java-11-tutorial/
https://www.opsian.com/blog/javas-new-zgc-is-very-exciting/


=== Garbage collection performance and tuning

=== !

*allocate less*

=== THE END

=== Sins of GC tunning

* Premature GC tuning, don't do it if you don't need it
* Not knowing about GC ergonomy and adaptive size policy, probably
`-XX:MaxGCPauseMillis=<nnn>`, `-XX:GCTimeRatio=<nnn>` and `-Xmx` is all you need
to touch
* Faith that GC tuning can hide bad programming and architecture practices

=== Sins of GC tunning

* No systematic and holistic approach, lack of monitoring, performance tests
* stackoverflow.com and google.com are *NOT* the places where you will find
*YOUR* JVM parameters
* Lack of undertanding how JVM and OS work and interact

=== Sins of GC tunning

* Different GC characteristics of applications
** batch processing vs online
** Stateful and stateless applications

=== when tuning makes sens

* you know memory allocation pressure profile and you know it will likely not change
(for example batch jobs)
* you don't own the code, and there is nothing you can do about it

=== use tools

* gather logs (from long and representative period of time)
* use tools
** Censum
** GcEasy

=== Useful links

https://www.petefreitag.com/articles/gctuning/[Tuning Garbage Collection Outline]

* ilość wątków GC można kontrolować parametrem `-XX:ParallelGCThreads=<N>`,
* domyślnie dla maszyn o CPU<=8; N=CPU
* dla pozostałych przypadków N=5/8 CPU lub N=5/16 CPU

=== !

* więcej szczegółów, w pliku http://hg.openjdk.java.net/jdk8/jdk8/hotspot/file/87ee5ee27509/src/share/vm/oops/markOop.hpp[markOop.hpp]
* oraz tutaj, http://www.slideshare.net/cnbailey/memory-efficient-java[Memory Efficient Java]


=== Ergonomia ParallelGC

* jeśli cel maksymalnego czasu pauzy nie jest osiągniety, rozmiar tylko jednej
z generacji jest pomniejszany
* jeśli cel przepustowości nie jest osiągniety, rozmiary obydwu generacji są
powiększane, proporcjonalnie do czasu odśmiecania w każdej z nich

=== few important switches

* `-XX:NewRatio=<N>`, defines the ratio of the "Old" generation size to the generation
"Young", `N = Old / Young`, the default values depend on the platform and JDK version
* `-XX:MaxNewSize=<N>` and `-XX:NewSize=<N>`, defines the size of the Young generation
in bytes

=== !

* `-XX:SurvivorRatio=10`, determines the ratio of the Eden space size to
Survivor space
* `-XX:TargetSurvivorRatio=5` and `-XX:MaxTenuringThreshold=15`, target and
maximum lifetime of the object in the Survivor area

=== !

* `-XX:YoungGenerationSizeIncrement<T>` and
`-XX:TenuredGenerationSizeIncrement=<T>`, determine the size increase rate
generation, default 20%
* `-XX:AdaptiveSizeDecrementScaleFactor=<D>`, determines the factor by which
the generation size is reduced and it is T / D
* `-XX:+UseGCOverheadLimit`, controls when `OutOfMemoryError` is thrown,
by default, when> 98% of the time the application spends on GC, recovering> 2% of memory

=== more switches

* `-XX:+CMSConcurrentMTEnabled` and `-XX:ConcGCThreads=<N>`, number of threads
used by GC during concurrent phases
* `-XX:PrintAdaptiveSizePolicy`,displays information about area changes
* `-XX:+AdaptiveSizePolicy`, enables the policy of dynamic area resizing

=== !

* `-XX+UseCMSInitiatingOccupancyOnly` and `-XX:CMSInitiatingOccupancyFraction`,
Percentage of Old, forcing garbage collection in contrast to "throughput collectors", which are triggered when missing
available memory
* `-XX:+CMSClassUnloadingEnabled`, deleting classes during CMS phases
* `-XX:+CMSIncrementalMode`, forces regular CMS startup,
at the expense of application threads (deprecated)

=== !

A mixed collection can (and usually does) happen over multiple mixed garbage collection cycles. When a sufficient number of old regions are collected, G1 GC reverts to performing the young garbage collections until the next marking cycle completes. A number of flags listed and defined here control the exact number of old regions added to the CSets:

=== !

`–XX:G1MixedGCLiveThresholdPercent`: The occupancy threshold of live objects in the old region to be included in the mixed collection.

`–XX:G1HeapWastePercent`: The threshold of garbage that you can tolerate in the heap.


=== !

`–XX:G1MixedGCCountTarget`: The target number of mixed garbage collections within which the regions with at most G1MixedGCLiveThresholdPercent live data should be collected.

`–XX:G1OldCSetRegionThresholdPercent`: A limit on the max number of old regions that can be collected during a mixed collection.

=== even more on tuning

`-XX:G1ConcRefinementThreads` or even `-XX:ParallelGCThreads`. If the concurrent refinement threads cannot keep up with the amount of filled buffers, then the mutator threads own and handle the processing of the buffers - usually something that you should strive to avoid.

=== !

-XX:+G1SummarizeRSetStats with the period set to one -XX:G1SummarizeRSetStatsPeriod=1, will
print RSet stats.

=== !

`-XX:G1RSetUpdatingPauseTimePercent=10`. This flag sets a percent target amount (defaults to 10 percent of the pause time goal) that G1 GC should spend in updating RSets during a GC evacuation pause. You can increase or decrease the percent value, so as to spend more or less (respectively) time in updating the RSets during the stop-the-world (STW) GC pause and let the concurrent refinement threads deal with the update buffers accordingly.

=== !

If you see high times during reference processing then please turn on parallel reference processing by enabling the following option on the command line `-XX:+ParallelRefProcEnabled`.

=== !

When there are no more free regions to promote to the old generation or to copy to the survivor space, and the heap cannot expand since it is already at its maximum, an evacuation failure occurs.

This is **REALLY EXPENSIVE**

=== !

Find out if the failures are a side effect of over-tuning - Get a simple baseline with min and max heap and a realistic pause time goal: Remove any additional heap sizing such as -Xmn, -XX:NewSize, -XX:MaxNewSize, -XX:SurvivorRatio, etc. Use only -Xms, -Xmx and a pause time goal -XX:MaxGCPauseMillis.

=== !

If the problem persists even with the baseline run and if humongous allocations (see next section below) are not the issue - the corrective action is to increase your Java heap size, if you can, of course

=== !

If increasing the heap size is not an option and if you notice that the marking cycle is not starting early enough for G1 GC to be able to reclaim the old generation then drop your -XX:InitiatingHeapOccupancyPercent. The default for this is 45% of your total Java heap. Dropping the value will help start the marking cycle earlier. Conversely, if the marking cycle is starting early and not reclaiming much, you should increase the threshold above the default value to make sure that you are accommodating for the live data set for your application.

=== !

If concurrent marking cycles are starting on time, but are taking a lot of time to finish; and hence are delaying the mixed garbage collection cycles which will eventually lead to an evacuation failure since old generation is not timely reclaimed; increase the number of concurrent marking threads using the command line option: -XX:ConcGCThreads.

=== !

If "to-space" survivor is the issue, then increase the -XX:G1ReservePercent. The default is 10% of the Java heap. G1 GC creates a false ceiling and reserves the memory, in case there is a need for more "to-space". Of course, G1 GC caps it off at 50%, since we do not want the end-user to set it to a very large value.

=== !

To help explain the cause of evacuation failure, we should use a very useful
option: `-XX:+PrintAdaptiveSizePolicy`.
This option will provide many ergonomic details that are purposefully kept out
of the `-XX:+PrintGCDetails` option.

== q&a
